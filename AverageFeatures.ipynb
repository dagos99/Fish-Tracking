{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_parts = [\n",
    "            'mouth', 'eye', 'skull', 'upper tail bone', 'lower tail bone',\n",
    "            'upper tail', 'lower tail', 'pectoral fin', 'anal fin start',\n",
    "            'anal fin mid', 'dorsal fin_base', 'dorsal fin_tip', 'stomach', 'middle'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(data_numeric, target_length=141, body_parts=None, num_individuals=8):\n",
    "    if body_parts is None:\n",
    "        body_parts = [\n",
    "            'mouth', 'eye', 'skull', 'upper tail bone', 'lower tail bone',\n",
    "            'upper tail', 'lower tail', 'pectoral fin', 'anal fin start',\n",
    "            'anal fin mid', 'dorsal fin_base', 'dorsal fin_tip', 'stomach', 'middle'\n",
    "        ]\n",
    "\n",
    "    def process_column(column, target_length):\n",
    "        result_array = np.zeros(target_length)\n",
    "        non_nan_indices = np.where(~column.isna())[0]\n",
    "        if len(non_nan_indices) > 1:\n",
    "            valid_values = column[non_nan_indices]\n",
    "            differences = np.diff(valid_values)\n",
    "            for i, diff in enumerate(differences):\n",
    "                result_array[non_nan_indices[i + 1]] = diff\n",
    "        return result_array\n",
    "\n",
    "    features_per_individual_and_bodypart = {}\n",
    "    \n",
    "    for individual in range(1, num_individuals + 1):\n",
    "        column_offset = (individual - 1) * len(body_parts)\n",
    "\n",
    "        for i, body_part in enumerate(body_parts):\n",
    "            x_col_name = f'x.{column_offset + i}' if column_offset + i > 0 else 'x'\n",
    "            y_col_name = f'y.{column_offset + i}' if column_offset + i > 0 else 'y'\n",
    "\n",
    "            if x_col_name in data_numeric.columns and y_col_name in data_numeric.columns:\n",
    "                delta_x = process_column(data_numeric[x_col_name], target_length)\n",
    "                delta_y = process_column(data_numeric[y_col_name], target_length)\n",
    "\n",
    "                if len(delta_x) > 0 and len(delta_y) > 0:\n",
    "                    speed = np.insert(np.sqrt(delta_x**2 + delta_y**2), 0, 0)\n",
    "                    direction = np.insert(np.arctan2(delta_y, delta_x), 0, 0)\n",
    "                    direction_degrees = np.degrees(direction)\n",
    "                    features_per_individual_and_bodypart[f'individual{individual}_{body_part}'] = pd.DataFrame({\n",
    "                        'Speed': speed,\n",
    "                        'Direction': direction_degrees\n",
    "                    })\n",
    "\n",
    "    return features_per_individual_and_bodypart\n",
    "\n",
    "\n",
    "def calculate_average_features(features_per_individual_and_bodypart):\n",
    "    average_features_per_individual = {}\n",
    "\n",
    "    for key, df in features_per_individual_and_bodypart.items():\n",
    "        individual_number = key.split('_')[0]\n",
    "\n",
    "        if isinstance(df, pd.Series):\n",
    "            df = df.to_frame()\n",
    "\n",
    "        if individual_number in average_features_per_individual:\n",
    "            average_features_per_individual[individual_number] = pd.concat([\n",
    "                average_features_per_individual[individual_number],\n",
    "                df\n",
    "            ], axis=1)\n",
    "        else:\n",
    "            average_features_per_individual[individual_number] = df\n",
    "\n",
    "    for individual, combined_df in average_features_per_individual.items():\n",
    "        speed_columns = [col for col in combined_df.columns if 'Speed' in col]\n",
    "        direction_columns = [col for col in combined_df.columns if 'Direction' in col]\n",
    "        average_speed = combined_df[speed_columns].mean(axis=1)\n",
    "        average_direction = combined_df[direction_columns].mean(axis=1)\n",
    "\n",
    "        average_features_per_individual[individual] = pd.DataFrame({\n",
    "            'Speed': average_speed,\n",
    "            'Direction': average_direction\n",
    "        })\n",
    "\n",
    "    return average_features_per_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_video_data_numeric = pd.read_csv('Collecteddata_first_video.csv', skiprows=3)\n",
    "first_video_data = calculate_features(first_video_data_numeric, target_length=141, body_parts=body_parts, num_individuals=8)\n",
    "first_video_data_individual = calculate_average_features(first_video_data)\n",
    "data_first_video = [df.values for df in first_video_data_individual.values()]\n",
    "first_video_data_padded = pad_sequences(data_first_video, padding='post', dtype='float32')\n",
    "\n",
    "second_video_data_numeric = pd.read_csv('new_Collecteddata_second_video.csv', skiprows=3)\n",
    "second_video_data = calculate_features(second_video_data_numeric, target_length=56, body_parts=body_parts, num_individuals=11)\n",
    "second_video_data_individual = calculate_average_features(second_video_data)\n",
    "data_second_video = [df.values for df in second_video_data_individual.values()]\n",
    "second_video_data_padded = pad_sequences(data_second_video, padding='post', dtype='float32')\n",
    "\n",
    "# species 0 black\n",
    "# species 1 yellow\n",
    "# species 2 grey\n",
    "# species 3 - the one that test video has but training video doesnt\n",
    "firs_video_labels = [0, 0, 2, 2, 1, 2, 1, 1]\n",
    "firs_video_labels = np.array(firs_video_labels)\n",
    "firs_video_labels_categorical = to_categorical(firs_video_labels)\n",
    "\n",
    "second_video_labels = [0, 1, 0, 2, 1, 3, 3, 1, 1, 1, 3]\n",
    "second_video_labels = np.array(second_video_labels)\n",
    "second_video_labels_categorical = to_categorical(second_video_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_species = 4\n",
    "first_video_number_of_individuals = 8\n",
    "second_video_number_of_individuals = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHOOSE WHICH ONE USE FOR TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = first_video_data_padded\n",
    "train_labels = firs_video_labels_categorical\n",
    "test_data_padded = second_video_data_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', input_shape=input_shape),\n",
    "        Dense(number_of_species, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAIME\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1145455.3750 - accuracy: 0.0000e+00 - val_loss: 14.5916 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 915187.0000 - accuracy: 0.0000e+00 - val_loss: 12.0207 - val_accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 344212.1250 - accuracy: 0.0000e+00 - val_loss: 8.0449 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 107021.1016 - accuracy: 0.0000e+00 - val_loss: 10.3314 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 26380.5156 - accuracy: 0.2000 - val_loss: 6.0817 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 14.2876 - accuracy: 0.0000e+00 - val_loss: 2.8460 - val_accuracy: 0.3333\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 2.8445 - accuracy: 0.2000 - val_loss: 2.7972 - val_accuracy: 0.3333\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 7.2138 - accuracy: 0.2000 - val_loss: 2.9270 - val_accuracy: 0.3333\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 2.2328 - accuracy: 0.4000 - val_loss: 2.7463 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 2.1802 - accuracy: 0.4000 - val_loss: 3.1936 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 85.6641 - accuracy: 0.4000 - val_loss: 3033.6550 - val_accuracy: 0.6667\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 446.3443 - accuracy: 0.0000e+00 - val_loss: 15326.2588 - val_accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 354.5351 - accuracy: 0.4000 - val_loss: 3.0316 - val_accuracy: 0.6667\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 79.7292 - accuracy: 0.0000e+00 - val_loss: 6984.5103 - val_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 136.4577 - accuracy: 0.2000 - val_loss: 24.9579 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1456.1135 - accuracy: 0.2000 - val_loss: 308.1726 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 45.9829 - accuracy: 0.2000 - val_loss: 2521.9424 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 6168.7798 - accuracy: 0.4000 - val_loss: nan - val_accuracy: 0.3333\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 273ms/step - loss: nan - accuracy: 0.2000 - val_loss: nan - val_accuracy: 0.3333\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 297ms/step - loss: nan - accuracy: 0.2000 - val_loss: nan - val_accuracy: 0.3333\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.3853 - accuracy: 0.6667 - val_loss: 6.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 70.3834 - accuracy: 0.5000 - val_loss: 3.0928 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 34.2090 - accuracy: 0.3333 - val_loss: 3.6180 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 694.9241 - accuracy: 0.3333 - val_loss: 6.7058 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 4.3735 - accuracy: 0.6667 - val_loss: 6.6930 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 4.6283 - accuracy: 0.5000 - val_loss: 9.7347 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 22.1272 - accuracy: 0.3333 - val_loss: 10.3333 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 5.3248 - accuracy: 0.3333 - val_loss: 18.7946 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 4.5006 - accuracy: 0.3333 - val_loss: 3.6812 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 4.8003 - accuracy: 0.1667 - val_loss: 9.1167 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "n_splits = 3\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in skf.split(train_data, train_labels):\n",
    "    X_train, X_val = data_padded[train_index], data_padded[test_index]\n",
    "    y_train, y_val = labels_categorical[train_index], labels_categorical[test_index]\n",
    "\n",
    "    model = create_model((data_padded.shape[1], data_padded.shape[2]), len(labels_categorical[0]))\n",
    "    history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_fish_detection.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 142, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, 142, 2), dtype=tf.float32, name='lstm_28_input'), name='lstm_28_input', description=\"created by layer 'lstm_28_input'\"), but it was called on an input with incompatible shape (None, 57, 2).\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000265D5CDD040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[2 2 2 2 1 2 2 0 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Cargar el modelo\n",
    "model_loaded = load_model('model_fish_detection.h5')\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = model_loaded.predict(test_data_padded)\n",
    "\n",
    "# Convertir las probabilidades de predicciones a clases concretas\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Imprimir la clase predicha\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_video_labels =   [0, 1, 0, 2, 1, 3, 3, 1, 1, 1, 3]\n",
    "predicted_test = [2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
