{"cells":[{"cell_type":"markdown","metadata":{},"source":["# THE FOLLOWING NOTEBOOK HAS BE RUN ON KAGGLE"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"execution":{"iopub.execute_input":"2024-02-20T14:21:07.882309Z","iopub.status.busy":"2024-02-20T14:21:07.882031Z","iopub.status.idle":"2024-02-20T14:21:08.656615Z","shell.execute_reply":"2024-02-20T14:21:08.655495Z","shell.execute_reply.started":"2024-02-20T14:21:07.882283Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["## Creating and Copying Directories in Kaggle Environment\n","\n","This code is designed to manage directories and copy data within the Kaggle environment.\n","\n","### Libraries Imported:\n","\n","- **os**: Provides a way of using operating system dependent functionality, such as reading or writing to the file system.\n","- **shutil**: Offers a higher-level file operation interface which includes functions to copy and remove directories.\n","\n","### Directory Management:\n","\n","- The code first checks if the directory `/kaggle/working/fish-tracking-dataset` exists.\n","- If the directory doesn't exist, it creates the directory using the `os.makedirs()` function. *(Note: This part of the code is commented out.)*\n","\n","### Data Copying:\n","\n","- The `shutil.copytree()` function is used to copy the entire directory tree from `/kaggle/input/fish-tracking-dataset` to `/kaggle/working/fish-tracking-dataset`. This means all files and sub-directories within the source directory will be copied to the destination directory.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T16:03:00.810343Z","iopub.status.busy":"2024-02-20T16:03:00.809927Z","iopub.status.idle":"2024-02-20T16:03:06.861400Z","shell.execute_reply":"2024-02-20T16:03:06.860474Z","shell.execute_reply.started":"2024-02-20T16:03:00.810315Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","import os\n","#if not os.path.exists('/kaggle/working/fish-tracking-dataset'):\n"," #         os.makedirs('/kaggle/working/fish-tracking-dataset')\n","shutil.copytree('/kaggle/input/fish-tracking-dataset', '/kaggle/working/fish-tracking-dataset')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:36:41.034122Z","iopub.status.busy":"2024-02-23T17:36:41.033501Z","iopub.status.idle":"2024-02-23T17:36:54.883673Z","shell.execute_reply":"2024-02-23T17:36:54.882539Z","shell.execute_reply.started":"2024-02-23T17:36:41.034095Z"},"trusted":true},"outputs":[],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:36:54.886260Z","iopub.status.busy":"2024-02-23T17:36:54.885887Z","iopub.status.idle":"2024-02-23T17:37:06.287552Z","shell.execute_reply":"2024-02-23T17:37:06.286594Z","shell.execute_reply.started":"2024-02-23T17:36:54.886225Z"},"trusted":true},"outputs":[],"source":["!pip install pyyaml"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:37:06.289392Z","iopub.status.busy":"2024-02-23T17:37:06.289007Z","iopub.status.idle":"2024-02-23T17:38:02.682284Z","shell.execute_reply":"2024-02-23T17:38:02.681333Z","shell.execute_reply.started":"2024-02-23T17:37:06.289340Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","import os\n","#if not os.path.exists('/kaggle/working/fish-tracking-dataset'):\n"," #         os.makedirs('/kaggle/working/fish-tracking-dataset')\n","shutil.copytree('/kaggle/input/deepfish/Prepared_Deepfish', '/kaggle/working/deepfish')"]},{"cell_type":"markdown","metadata":{},"source":["## Loading YOLO Models with Ultralytics\n","\n","This code snippet demonstrates how to load YOLO (You Only Look Once) models using the Ultralytics library.\n","\n","### Libraries Imported:\n","\n","- **ultralytics**: The Ultralytics library provides functionalities for the YOLO object detection framework.\n","\n","### Loading Models:\n","\n","There are multiple ways to load a YOLO model using Ultralytics:\n","\n","1. **Building a New Model from YAML**:\n","   - `model = YOLO('yolov8n.yaml')`: This line of code builds a new YOLO model based on the architecture specified in the 'yolov8n.yaml' file. *(Note: This line is commented out in the provided code.)*\n","\n","2. **Loading a Pretrained Model**:\n","   - `model = YOLO('yolov8s.pt')`: This line loads a pretrained YOLO model from the 'yolov8s.pt' file. Using pretrained models is recommended when training on a new dataset as it can leverage the knowledge from the pretrained weights.\n","\n","3. **Building from YAML and Transferring Weights**:\n","   - `model = YOLO('yolov8n.yaml').load('yolov8n.pt')`: This line first builds a YOLO model from the 'yolov8n.yaml' file and then transfers the weights from the 'yolov8n.pt' file. *(Note: This line is commented out in the provided code.)*\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:40:11.126089Z","iopub.status.busy":"2024-02-23T17:40:11.125329Z","iopub.status.idle":"2024-02-23T17:40:15.820380Z","shell.execute_reply":"2024-02-23T17:40:15.819364Z","shell.execute_reply.started":"2024-02-23T17:40:11.126058Z"},"trusted":true},"outputs":[],"source":["from ultralytics import YOLO\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","# Load a model\n","#model = YOLO('yolov8n.yaml')  # build a new model from YAML\n","model = YOLO('yolov8s.pt')  # load a pretrained model (recommended for training)\n","#model = YOLO('yolov8n.yaml').load('yolov8n.pt')  # build from YAML and transfer weights"]},{"cell_type":"markdown","metadata":{},"source":["## Creating and Saving a YAML Configuration File\n","\n","This code snippet demonstrates how to define a configuration in Python, and then save it as a YAML (YAML Ain't Markup Language) file using the `yaml` library.\n","\n","### Libraries Imported:\n","\n","- **yaml**: The `yaml` library provides functionalities for YAML parsing, which is a human-readable data serialization format.\n","\n","### Configuration Data:\n","\n","- A Python dictionary named `config` is defined, which contains various configuration settings:\n","  - `path`: Working directory path.\n","  - `train`: Relative path to the training images.\n","  - `val`: Relative path to the validation images.\n","  - `nc`: Number of classes.\n","  - `names`: List of class names.\n","  - `fl_gamma`: (Commented out) Can be used to specify a focal loss gamma value if needed.\n","\n","### Saving to YAML File:\n","\n","- The desired file path for the YAML file is specified as `yaml_file_path`.\n","- The `with` statement is used to open this file in write mode.\n","- The `yaml.dump()` function is then used to write the `config` dictionary to the file in YAML format.\n","- Finally, a confirmation message is printed to indicate the successful saving of the configuration to the YAML file.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:40:26.109033Z","iopub.status.busy":"2024-02-23T17:40:26.108463Z","iopub.status.idle":"2024-02-23T17:40:26.117722Z","shell.execute_reply":"2024-02-23T17:40:26.116646Z","shell.execute_reply.started":"2024-02-23T17:40:26.109001Z"},"trusted":true},"outputs":[],"source":["import yaml\n","\n","# Define your configuration data as a Python dictionary\n","config = {\n","    #'path': '/kaggle/working/fishtrach-yolo',\n","    #'path': '/kaggle/working',\n","    'path': '/kaggle/working/deepfish',\n","    'train': 'train/images',  # train images (relative to 'path') 4 images\n","    'val': 'val/images',      # val images (relative to 'path') 4 images\n","    'nc': 1,                   # Number of classes\n","    'names': ['Fish'],         # Class names\n","    # 'fl_gamma': 2.0          # Uncomment this line if needed\n","}\n","\n","# Define the file path where you want to save the YAML file\n","yaml_file_path = '/kaggle/working/config.yaml'  # Update with your desired path and file name\n","#yaml_file_path = '/kaggle/working/config.yaml'\n","\n","# Write the YAML data to the file\n","with open(yaml_file_path, 'w') as yaml_file:\n","    yaml.dump(config, yaml_file)\n","\n","print(f\"YAML configuration file saved at: {yaml_file_path}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Training the YOLO Model with Ultralytics\n","\n","This code snippet demonstrates how to train a YOLO model using the Ultralytics library based on a specified configuration.\n","\n","### Model Training:\n","\n","The `train()` method of the YOLO model is called with the following parameters:\n","\n","- **data**: Path to the YAML configuration file that contains dataset paths, class names, and other related information.\n","- **epochs**: Number of training epochs. An epoch is one complete forward and backward pass of all the training examples.\n","- **imgsz**: Image size for training. All training images will be resized to this size.\n","- **pretrained**: If set to `True`, the model will use pretrained weights. This can help in achieving better accuracy faster.\n","- **name**: Name of the training run. Useful for distinguishing between different training sessions.\n","- **patience**: Number of epochs with no improvement after which training will be stopped. Helps in preventing overfitting.\n","- **flipud**: Probability of flipping an image vertically during data augmentation.\n","- **batch**: Batch size for training. Determines the number of samples that will be used in each iteration to update the model's weights.\n","- **optimizer**: Optimization algorithm to be used. In this case, Stochastic Gradient Descent (SGD) is used.\n","- **augment**: If set to `True`, data augmentation techniques will be applied to the training images. This can help in improving the model's generalization.\n","\n","The result of the training process is stored in the `results` variable.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:44:24.243102Z","iopub.status.busy":"2024-02-23T17:44:24.242749Z","iopub.status.idle":"2024-02-23T18:19:49.603781Z","shell.execute_reply":"2024-02-23T18:19:49.602693Z","shell.execute_reply.started":"2024-02-23T17:44:24.243074Z"},"trusted":true},"outputs":[],"source":["results = model.train(data='/kaggle/working/config.yaml',\n","                      epochs=20,\n","                      imgsz=640,\n","                      pretrained = True ,\n","                      name= \"training_deepfish\",\n","                      patience = 35,\n","                      flipud=0.5,\n","                      batch = 32,\n","                      optimizer = 'SGD',\n","                      augment = True\n","                      )"]},{"cell_type":"markdown","metadata":{},"source":["## Validating the YOLO Model with Ultralytics\n","\n","This code snippet demonstrates how to validate a trained YOLO model using the Ultralytics library.\n","\n","### Model Loading:\n","\n","- **model**: The YOLO model is loaded using the `YOLO` class from Ultralytics. The path to the best weights from a previous training run is provided to initialize the model.\n","\n","### Model Validation:\n","\n","- **results**: The `val()` method of the YOLO model is called without any parameters to validate the model using the default settings.\n","\n","### Validation with Different Confidence Thresholds:\n","\n","The model is further validated using different confidence thresholds to understand its performance at various levels of confidence:\n","\n","- The `for` loop iterates over a list of confidence thresholds: `0.25`, `0.15`, and `0.05`.\n","- For each confidence threshold, the `val()` method is called with the following parameters:\n","  - **name**: A custom name for the validation run, indicating the confidence threshold used.\n","  - **conf**: The confidence threshold. Only detections with a confidence score above this threshold will be considered.\n","  - **iou**: Intersection over Union (IoU) threshold set to `0.8`. It determines how much overlap an accurate detection should have with the ground truth for it to be considered correct.\n","\n","This validation process helps in understanding the model's performance at different confidence levels and can guide decisions on the optimal confidence threshold to use for detections.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T17:53:28.007641Z","iopub.status.busy":"2024-02-20T17:53:28.007233Z","iopub.status.idle":"2024-02-20T17:54:38.532530Z","shell.execute_reply":"2024-02-20T17:54:38.531522Z","shell.execute_reply.started":"2024-02-20T17:53:28.007612Z"},"trusted":true},"outputs":[],"source":["model = YOLO('/kaggle/working/runs/detect/training_doubleDataset/weights/best.pt')\n","results = model.val()\n","for i in [0.25,0.15,0.05]:\n","  results = model.val(name= f'cofidence: {i}', conf= i , iou=0.8)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T08:47:05.666493Z","iopub.status.busy":"2024-02-16T08:47:05.666126Z","iopub.status.idle":"2024-02-16T08:47:05.793982Z","shell.execute_reply":"2024-02-16T08:47:05.792804Z","shell.execute_reply.started":"2024-02-16T08:47:05.666464Z"},"trusted":true},"outputs":[],"source":["model = YOLO('/kaggle/working/runs/detect/fish_small/weights/best.pt')"]},{"cell_type":"markdown","metadata":{},"source":["## Importing Essential Libraries for Image Processing and Visualization\n","\n","This code snippet imports various Python libraries that are commonly used for image processing, data manipulation, and visualization.\n","\n","### Libraries Imported:\n","\n","- **pandas**: A powerful library for data manipulation and analysis, particularly with structured data.\n","- **numpy**: Fundamental package for numerical computations in Python.\n","- **PIL**: Python Imaging Library (also known as Pillow) is used for opening, manipulating, and saving image files.\n","- **Image**: A module from PIL to specifically handle image operations.\n","- **IPython.display**: Provides functionalities to display objects within Jupyter.\n","- **matplotlib.pyplot**: Provides a MATLAB-like plotting framework in Python.\n","- **glob**: Useful for retrieving files/pathnames matching a specified pattern.\n","- **random**: Provides functions to generate random numbers.\n","- **cv2**: OpenCV library, a powerful tool for computer vision tasks.\n","- **warnings**: Used to control the behavior of warning messages in Python."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T17:55:06.425502Z","iopub.status.busy":"2024-02-20T17:55:06.425080Z","iopub.status.idle":"2024-02-20T17:55:06.432344Z","shell.execute_reply":"2024-02-20T17:55:06.431221Z","shell.execute_reply.started":"2024-02-20T17:55:06.425466Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import PIL \n","from PIL import Image\n","from IPython.display import display\n","import matplotlib.pyplot as plt\n","from glob import glob\n","import random\n","import cv2\n","import warnings\n","warnings.simplefilter('ignore')"]},{"cell_type":"markdown","metadata":{},"source":["## Displaying Random Sample Images from Validation Set\n","\n","This code snippet is designed to randomly select and display images from the validation set.\n","\n","### Setting Up Paths and Parameters:\n","\n","- **root_path**: Specifies the path where validation images are located. The `*` at the end of the path is a wildcard that matches all files in the directory.\n","- **num_samples**: Number of random sample images to display, set to 4.\n","\n","### Retrieving and Sampling Images:\n","\n","- **images_data**: Uses `glob(root_path)` to retrieve all file paths that match the specified pattern, effectively getting paths to all images in the directory.\n","- **random_image**: Randomly selects `num_samples` image paths from `images_data` using `random.sample()`.\n","\n","### Displaying Images:\n","\n","- A matplotlib figure is created with a specified size.\n","- A `for` loop iterates over the range of `num_samples`:\n","  - For each iteration, a subplot is created.\n","  - The image is read using `cv2.imread()` and displayed using `plt.imshow()`.\n","  - The axis labels are turned off for a cleaner display.\n","\n","### Visual Output:\n","\n","- The output will be a 2x2 grid displaying four randomly selected images from the validation set.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T17:55:07.227287Z","iopub.status.busy":"2024-02-20T17:55:07.226952Z","iopub.status.idle":"2024-02-20T17:55:09.176055Z","shell.execute_reply":"2024-02-20T17:55:09.175120Z","shell.execute_reply.started":"2024-02-20T17:55:07.227259Z"},"trusted":true},"outputs":[],"source":["root_path = '/kaggle/working/val/images/*'\n","num_samples = 4\n","images_data = glob(root_path)\n","random_image = random.sample(images_data, num_samples)\n","\n","plt.figure(figsize=(12,10))\n","for i in range(num_samples):\n","    plt.subplot(2,2,i+1)\n","    plt.imshow(cv2.imread(random_image[i]))\n","    plt.axis('off')"]},{"cell_type":"markdown","metadata":{},"source":["## Predicting and Displaying Object Detections on Sample Images\n","\n","This code snippet is designed to predict object detections on a set of randomly selected images using the trained YOLO model and then display the results.\n","\n","### Predicting Detections:\n","\n","- An empty list `images` is initialized to store the processed images with bounding boxes.\n","- A `for` loop iterates over the range of `num_samples`:\n","  - For each image, the YOLO model's `predict()` method is called to get the detection results.\n","  - The results include bounding boxes (`box`), class names (`names`), and other attributes.\n","  - A series of print statements display information about each detected object:\n","    - Total number of detected fish in the image.\n","    - Label of the detected object (e.g., \"Fish\").\n","    - Coordinates of the bounding box.\n","    - Confidence score of the detection.\n","\n","### Storing Processed Images:\n","\n","- The `output.plot()` method is used to generate an image with bounding boxes drawn around detected objects.\n","- The color channels of the image are reversed (`[:, :, ::-1]`) to convert from BGR to RGB format (as OpenCV reads images in BGR format by default).\n","- The processed image is then appended to the `images` list.\n","\n","### Visual Output:\n","\n","- The `images` list will contain the randomly selected sample images with bounding boxes drawn around detected objects, ready for visualization.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-02-20T17:55:09.178237Z","iopub.status.busy":"2024-02-20T17:55:09.177872Z","iopub.status.idle":"2024-02-20T17:55:09.665191Z","shell.execute_reply":"2024-02-20T17:55:09.664466Z","shell.execute_reply.started":"2024-02-20T17:55:09.178204Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["images = []\n","for i in range(num_samples):\n","    yolo_outputs = model.predict(random_image[i])\n","    output = yolo_outputs[0]\n","    box = output.boxes\n","    names = output.names\n","    print('**********************')\n","    for j in range(len(box)):\n","        labels = names[box.cls[j].item()]\n","        coordinates = box.xyxy[j].tolist()\n","        confidence = np.round(box.conf[j].item(), 2)\n","        print(f'In this image {len(box)} fish has been detected.')\n","        print(f'Fish {j + 1} is: {labels}')\n","        print(f'Coordinates are: {coordinates}')\n","        print(f'Confidence is: {confidence}')\n","        print('-------')\n","        \n","    # Store the image in the 'images' list\n","    images.append(output.plot()[:, :, ::-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T17:55:09.666563Z","iopub.status.busy":"2024-02-20T17:55:09.666273Z","iopub.status.idle":"2024-02-20T17:55:11.565089Z","shell.execute_reply":"2024-02-20T17:55:11.564200Z","shell.execute_reply.started":"2024-02-20T17:55:09.666536Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,10))\n","for i, img in enumerate(images):\n","    plt.subplot(2, 2, i + 1)\n","    plt.imshow(img)\n","    plt.axis('off') "]},{"cell_type":"markdown","metadata":{},"source":["## Visualizing Training and Validation Losses\n","\n","This code snippet is designed to visualize the training and validation losses over epochs for both box and class losses.\n","\n","### Data Preprocessing:\n","\n","- **Removing Spaces**: The leading and trailing spaces from the column names of the `result` dataframe are removed using the `str.strip()` method.\n","\n","### Extracting Relevant Data:\n","\n","- **epoch_column**: Extracts the epoch numbers.\n","- **box_train_losses** and **box_val_losses**: Extracts the training and validation box losses, respectively.\n","- **cls_train_losses** and **cls_val_losses**: Extracts the training and validation class losses, respectively.\n","\n","### Plotting Losses:\n","\n","- A figure with two subplots is created using `plt.figure()` and `plt.subplot()`.\n","- The `ggplot` style is applied to the plots for better visualization.\n","  \n","1. **Box Losses**:\n","   - The first subplot displays the training and validation box losses over epochs.\n","   - The `plt.plot()` function is used to plot the box losses against the epochs.\n","   - A grid is added for better readability.\n","   - Labels, title, and legend are added for clarity.\n","\n","2. **Class Losses**:\n","   - The second subplot displays the training and validation class losses over epochs.\n","   - The `plt.plot()` function is used to plot the class losses against the epochs.\n","   - A grid is added for better readability.\n","   - Labels, title, and legend are added for clarity.\n","\n","Finally, `plt.show()` is called to display the plots.\n","\n","### Visual Output:\n","\n","- The output will be two line plots side by side:\n","  - The left plot shows the training and validation box losses over epochs.\n","  - The right plot shows the training and validation class losses over epochs.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T08:48:31.580699Z","iopub.status.busy":"2024-02-16T08:48:31.580317Z","iopub.status.idle":"2024-02-16T08:48:31.609872Z","shell.execute_reply":"2024-02-16T08:48:31.608822Z","shell.execute_reply.started":"2024-02-16T08:48:31.580658Z"},"trusted":true},"outputs":[],"source":["result = pd.read_csv('/kaggle/working/runs/detect/fish_small/results.csv')\n","result.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T08:48:31.886799Z","iopub.status.busy":"2024-02-16T08:48:31.886427Z","iopub.status.idle":"2024-02-16T08:48:32.461906Z","shell.execute_reply":"2024-02-16T08:48:32.460743Z","shell.execute_reply.started":"2024-02-16T08:48:31.886768Z"},"trusted":true},"outputs":[],"source":["# Remove leading and trailing spaces from column names\n","result.columns = result.columns.str.strip()\n","\n","epoch_column = result['epoch']\n","box_train_losses = result['train/box_loss']\n","box_val_losses = result['val/box_loss']\n","cls_train_losses = result['train/cls_loss']\n","cls_val_losses = result['val/cls_loss']\n","\n","plt.figure(figsize=(12,5))\n","plt.style.use('ggplot')  # You can choose a style you prefer\n","plt.subplot(1,2,1)\n","plt.plot(epoch_column, box_train_losses, label='train_losses')\n","plt.plot(epoch_column, box_val_losses, label='val_losses')\n","plt.grid(True, linestyle='--', linewidth=0.5, color='gray')# Add a grid\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Train and Validation Box Losses')\n","plt.legend()\n","\n","plt.subplot(1,2,2)\n","plt.plot(epoch_column, cls_train_losses, label='train_losses')\n","plt.plot(epoch_column, cls_val_losses, label='val_losses')\n","plt.grid(True, linestyle='--', linewidth=0.5, color='gray')# Add a grid\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Train and Validation Class Losses')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T08:48:40.287714Z","iopub.status.busy":"2024-02-16T08:48:40.287268Z","iopub.status.idle":"2024-02-16T08:48:41.074409Z","shell.execute_reply":"2024-02-16T08:48:41.073492Z","shell.execute_reply.started":"2024-02-16T08:48:40.287676Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,8))\n","plt.imshow(cv2.imread('/kaggle/working/runs/detect/fish_small/results.png'))\n","plt.axis('off')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3624985,"sourceId":6301499,"sourceType":"datasetVersion"},{"datasetId":4464920,"sourceId":7657840,"sourceType":"datasetVersion"},{"datasetId":4468665,"sourceId":7663243,"sourceType":"datasetVersion"},{"datasetId":4485764,"sourceId":7687071,"sourceType":"datasetVersion"}],"dockerImageVersionId":30559,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
